<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Data update}
-->

ENCODExplorer: A compilation of metadata from ENCODE
====================================================================
Audrey Lemacon, Louis Gendron, Charles Joly Beauparlant and Arnaud Droit.

This package and the underlying ENCODExplorer code are distributed under 
the Artistic license 2.0. You are free to use and redistribute this software. 

"The ENCODE (Encyclopedia of DNA Elements) Consortium is an international 
collaboration of research groups funded by the National Human Genome Research 
Institute (NHGRI). The goal of ENCODE is to build a comprehensive parts list of 
functional elements in the human genome, including elements that act at the 
protein and RNA levels, and regulatory elements that control cells and 
circumstances in which a gene is active"^[source : [ENCODE Projet Portal ](https://www.encodeproject.org/)] .

However, data retrieval and downloading can be really time-consuming using 
the current web portal. 

This package has been designed to facilitate data access by compiling the 
metadata associated with files, experiments and datasets. 

We first extract the ENCODE schema from its public github repository. 
We then identify the main entities and their relationships with each other to 
rebuild the ENCODE database into a data.table. 
We also developped a function which can extract the essential metadata into 
an R object to aid data exploration.
We implemented time-saving features to select ENCODE files by querying their 
metadata and download them.

The data.table can be regenerated at will to query an up-to-date ENCODE
database locally.

This vignette will introduce how to update the local copy of the ENCODE data.

### Loading the ENCODExplorer package

```{r libraryLoad}
suppressMessages(library(ENCODExplorer))
```

### Data update

Updating ENCODExplorer's local cache of ENCODE metadata relies on two functions 
from the ENCODExplorer package: 
* **prepare_ENCODEdb**, which fectches all raw metadata from ENCODE's website
using its REST API, and 
* **export_ENCODEdb_matrix**, which converts that metadata into an easy to 
parse data.table used by ENCODExplorer's query functions.

Thus, the first step to updating the local cache of ENCODE data is to call
**prepare_ENCODEdb**. By default, the results are cached in the current work 
directory in a file called "tables.RDA". Since fetching ENCODE metadata 
is a lengthy process, it is advisable to fetch this data only once, then to rely
on the cached data:

```{r tables, eval=FALSE}
# The path (relative or absolute) to the future database
database_filename = "new.encode.rda"
tables = prepare_ENCODEdb(database_filename)
```

The resulting object is a list of data.table objects representing ENCODE
metadata. The meaning of the included columns is documented in ENCODE's
table schemas(https://github.com/ENCODE-DCC/encoded/tree/master/src/encoded/schemas),
and the interaction between those tables interact together can be [visualized
in svg format](https://www.encodeproject.org/profiles/graph.svg).

Once the data has been fetched, it can be converted into a data.table equivalent 
to the default encode_df using **export_ENCODEdb_matrix**:

```{r, eval=FALSE}
# The path (relative or absolute) to the database downloaded using
# prepare_ENCODEdb.
database_filename <- "new.encode.rda"
new_encode_df <- export_ENCODEdb_matrix(database_filename)
```

The whole process is time-consuming and memory intensive, and took two hours 
and at least 5Gb of RAM to complete on a modern PC.

### Using the updated data

You can use your new metadata by passing it to the queryEncode and downloadEncode 
functions using their *df* parameter:

```{r queryEncode, eval=FALSE}
query_results <- queryEncode(df = new_encode_df, assay = "switchgear",
                             target ="elavl1", file_format = "bed" , fixed = F)
downloadEncode(df = new_encode_df, file_acc = query_results$file_accession)
```

Be sure to use the same *df* data.table for both **queryEncode** and **downloadEncode**.

You can also use the generated data.table database for your own purposes. The
imputed database model is available in the [dedicated vignette](DBmodel.html)